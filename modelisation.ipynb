{
 "cells": [
  {
   "cell_type": "raw",
   "id": "01edefdd-244a-4a5d-9f4e-17e49f84dc8d",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Analyse Exploratoire\n",
    "\n",
    "# ### Import des modules\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ### Analyse Exploratoire\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "building_consumption = pd.read_csv(\"building_energy_benchmarking.csv\")\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# On regarde comment un batiment est défini dans ce jeu de données \n",
    "building_consumption.head()\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "building_consumption.shape\n",
    "\n",
    "\n",
    "# ## Préparation du DF de travail\n",
    "\n",
    "# #### Inspection du DF de base\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "# On regarde le nombre de valeurs manquantes par colonne ainsi que leur type \n",
    "building_consumption.info()\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "building_consumption[\"DataYear\"].nunique()\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "building_consumption[\"City\"].nunique()\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "building_consumption[\"State\"].nunique()\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "building_consumption[\"Comments\"].nunique()\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "building_consumption[\"CouncilDistrictCode\"].nunique()\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "building_consumption[\"ZipCode\"].nunique()\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "building_consumption_clean = building_consumption.copy()\n",
    "\n",
    "\n",
    "# On peut supprimer les colonnes **DataYear**, **City**, **State** car elles ont toutes la même valeur. et **Comments** car il n'a pas de valeur.\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "building_consumption_clean = building_consumption_clean.drop([\"DataYear\", \"City\", \"State\", \"Comments\"], axis=1)\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "building_consumption_clean = building_consumption_clean.drop([\"Latitude\", \"Longitude\"], axis=1)\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "building_consumption[\"Neighborhood\"].value_counts()\n",
    "\n",
    "\n",
    "# On peut également supprimer l'**adresse**, le **ZipCode**, le **TaxParcelIdentificationNumber** et **CouncilDistrictCode** car on a le voisinage.\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "building_consumption_clean[\"Neighborhood\"] = (\n",
    "    building_consumption_clean[\"Neighborhood\"].replace({\n",
    "        'Central': 'CENTRAL',\n",
    "        'North': 'NORTH',\n",
    "        'Northwest': 'NORTHWEST',\n",
    "        'Ballard': 'BALLARD',\n",
    "        'Delridge': 'DELRIDGE',\n",
    "        'DELRIDGE NEIGHBOHORDOODS': 'DELRIDGE'\n",
    "    })\n",
    ")\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "building_consumption_clean = building_consumption_clean.drop([\"Address\", \"ZipCode\", \"TaxParcelIdentificationNumber\", \"CouncilDistrictCode\"], axis=1)\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "building_consumption[\"BuildingType\"].value_counts()\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "building_consumption_clean = building_consumption_clean[\n",
    "    building_consumption_clean[\"BuildingType\"].isin([\"NonResidential\",\"Nonresidential COS\"])\n",
    "]\n",
    "\n",
    "\n",
    "# #### Comparer les unités d'énergies\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "building_consumption_clean[\n",
    "    ((building_consumption_clean[\"NaturalGas(therms)\"].isna()) | \n",
    "     (building_consumption_clean[\"NaturalGas(therms)\"] == 0)) &\n",
    "    ((building_consumption_clean[\"NaturalGas(kBtu)\"].notna()) & \n",
    "     (building_consumption_clean[\"NaturalGas(kBtu)\"] != 0))\n",
    "][[\"BuildingType\", \"NaturalGas(therms)\",\"NaturalGas(kBtu)\"]]\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "building_consumption_clean[\n",
    "    ((building_consumption_clean[\"Electricity(kWh)\"].isna()) | \n",
    "     (building_consumption_clean[\"Electricity(kWh)\"] == 0)) &\n",
    "    ((building_consumption_clean[\"Electricity(kBtu)\"].notna()) & \n",
    "     (building_consumption_clean[\"Electricity(kBtu)\"] != 0))\n",
    "][[\"BuildingType\", \"Electricity(kWh)\", \"Electricity(kBtu)\"]]\n",
    "\n",
    "\n",
    "# Toutes les colonnes ayant des valeurs en therms ou en kWh on leur équivalent en kBtu. On va donc supprimer ces colonnes.\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "building_consumption_clean = building_consumption_clean.drop([\"Electricity(kWh)\", \"NaturalGas(therms)\"], axis=1)\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "building_consumption_clean.columns\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "building_consumption_clean.shape\n",
    "\n",
    "\n",
    "# #### Données diverses\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "building_consumption_clean[\"YearsENERGYSTARCertified\"].value_counts()\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "building_consumption_clean[\"YearsENERGYSTARCertified\"] = (\n",
    "    building_consumption_clean[\"YearsENERGYSTARCertified\"]\n",
    "    .astype(str)\n",
    "    .apply(lambda x: re.findall(r\"\\d{4}\", x)[0] if re.findall(r\"\\d{4}\", x) else None)\n",
    ")\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "building_consumption_clean[\"YearsENERGYSTARCertified\"].value_counts()\n",
    "\n",
    "\n",
    "# #### DefaultData\n",
    "\n",
    "# **DefaultData** : Données estimées ou réelles\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "building_consumption_clean[\"DefaultData\"].value_counts()\n",
    "\n",
    "\n",
    "# C'est ce qu'on suppose qu'on devrait avoir comme données. False = c'est bon, corrigée au données réelles.\n",
    "\n",
    "# #### Compliance Status\n",
    "\n",
    "# **ComplianceStatus** : Conformité réglementaire du bâtiment\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "building_consumption_clean[\"ComplianceStatus\"].value_counts()\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "building_consumption_clean[building_consumption_clean[\"ComplianceStatus\"] == \"Error - Correct Default Data\"]\n",
    "\n",
    "\n",
    "# Ces bâtiment ont beaucoup de données. On va donc les garder.\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "building_consumption_clean[building_consumption_clean[\"ComplianceStatus\"] == \"Missing Data\"]\n",
    "\n",
    "\n",
    "# On peut supprimer ces lignes qui ont trop de valeurs manquantes.\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "building_consumption_clean = building_consumption_clean.drop([746], axis=0)\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "building_consumption_clean[building_consumption_clean[\"ComplianceStatus\"] == \"Non-Compliant\"]\n",
    "\n",
    "\n",
    "# #### Outlier\n",
    "\n",
    "# Outlier : Valeurs extrêmes identifiées\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "building_consumption_clean[\"Outlier\"].value_counts()\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "building_consumption_clean[\n",
    "    building_consumption_clean[\"Outlier\"].isin([\"Low outlier\"])\n",
    "][\"ListOfAllPropertyUseTypes\"]\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "building_consumption_clean[\n",
    "    building_consumption_clean[\"Outlier\"].isin([\"High outlier\"])\n",
    "][\"ListOfAllPropertyUseTypes\"]\n",
    "\n",
    "\n",
    "# Il est normal que les valeurs de Outlier soit High car ce sont des Data Center\n",
    "\n",
    "# #### Données mise à jour avec la météo\n",
    "\n",
    "# Comparer si les données qui prennent en compte la météo sont disponibles pour tous les bâtiments\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "building_consumption_clean[\n",
    "    (building_consumption_clean[\"SiteEUIWN(kBtu/sf)\"].isna() | \n",
    "     (building_consumption_clean[\"SiteEUIWN(kBtu/sf)\"] == 0))\n",
    "][[\"BuildingType\", \"SiteEUIWN(kBtu/sf)\", \"SiteEUI(kBtu/sf)\"]]\n",
    "\n",
    "\n",
    "# Nous avons quelques valeurs qui ne tiennent pas en compte les valeurs de la météo mais contiennent des valeurs qui n'en tiennent pas compte. On va donc garder ces deux colonnes.\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "building_consumption_clean.loc[[304, 578, 2670]]\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "building_consumption_clean = building_consumption_clean.drop([304, 578, 2670], axis=0)\n",
    "\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "\n",
    "building_consumption_clean[\"SiteEUI(kBtu/sf)\"].min()\n",
    "\n",
    "\n",
    "# Regardons plus en détail les lignes qui ont 0 & Nan\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "\n",
    "building_consumption_clean.loc[building_consumption_clean[\"SiteEUI(kBtu/sf)\"].idxmin()]\n",
    "\n",
    "\n",
    "# In[42]:\n",
    "\n",
    "\n",
    "building_consumption_clean[\"SiteEUI(kBtu/sf)\"].mean()\n",
    "\n",
    "\n",
    "# In[43]:\n",
    "\n",
    "\n",
    "building_consumption_clean[\"SiteEUI(kBtu/sf)\"].max()\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "building_consumption_clean[\"SiteEUIWN(kBtu/sf)\"].min()\n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "\n",
    "building_consumption_clean.loc[building_consumption_clean[\"SiteEUI(kBtu/sf)\"].idxmax()]\n",
    "\n",
    "\n",
    "# Ok pour le max, c'est un DataCenter\n",
    "# \n",
    "\n",
    "# In[46]:\n",
    "\n",
    "\n",
    "building_consumption_clean.loc[building_consumption_clean[\"SiteEUIWN(kBtu/sf)\"].idxmin()]\n",
    "\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "\n",
    "building_consumption_clean.shape\n",
    "\n",
    "\n",
    "# #### Valeurs vides\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "\n",
    "cols_to_check = [\n",
    "    \"SiteEUIWN(kBtu/sf)\",\n",
    "    \"SiteEnergyUse(kBtu)\",\n",
    "    \"SiteEnergyUseWN(kBtu)\",\n",
    "    \"SteamUse(kBtu)\",\n",
    "    \"Electricity(kBtu)\",\n",
    "    \"NaturalGas(kBtu)\"\n",
    "]\n",
    "\n",
    "\n",
    "# Vérifiez qu'il existe ou nous des lignes où toutes les valeurs sont égales à 0 ou NaN\n",
    "\n",
    "# In[49]:\n",
    "\n",
    "\n",
    "building_consumption_clean[\n",
    "    building_consumption_clean[cols_to_check].isna().all(axis=1) |   \n",
    "    (building_consumption_clean[cols_to_check] == 0).all(axis=1)   \n",
    "]\n",
    "\n",
    "\n",
    "# #### Matrice de corrélation de Pearson\n",
    "\n",
    "# In[50]:\n",
    "\n",
    "\n",
    "colonnes_correlation = [\n",
    "    'PropertyGFATotal', \n",
    "    'YearBuilt', \n",
    "    'NumberofFloors',\n",
    "    'ENERGYSTARScore', \n",
    "    'SiteEnergyUseWN(kBtu)', \n",
    "    'SiteEnergyUse(kBtu)', \n",
    "    'TotalGHGEmissions'\n",
    "]\n",
    "\n",
    "df_corr = building_consumption_clean[colonnes_correlation].copy()\n",
    "\n",
    "# 2. Calcul de la matrice de corrélation\n",
    "matrice_corr = df_corr.corr(method='pearson')\n",
    "\n",
    "# 3. Visualisation (Heatmap)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    matrice_corr, \n",
    "    annot=True, \n",
    "    cmap='coolwarm', \n",
    "    fmt=\".2f\",\n",
    "    linewidths=.5,\n",
    ")\n",
    "plt.title('Matrice de Corrélation')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# #### Consommation énergétique en fonction du voisinage\n",
    "\n",
    "# In[51]:\n",
    "\n",
    "\n",
    "building_consumption_clean.columns\n",
    "\n",
    "\n",
    "# In[52]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(\n",
    "    data=building_consumption_clean,\n",
    "    x=\"Neighborhood\",\n",
    "    y=\"SiteEUIWN(kBtu/sf)\"\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Distribution de SiteEUIWN(kBtu/sf) par Neighborhood\")\n",
    "plt.xlabel(\"Neighborhood\")\n",
    "plt.ylabel(\"SiteEUIWN(kBtu/sf)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# #### Lien entre l'année de construction et la consommation énergétique\n",
    "\n",
    "# In[53]:\n",
    "\n",
    "\n",
    "df = building_consumption_clean.copy()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(df[\"YearBuilt\"], df[\"SiteEUIWN(kBtu/sf)\"])\n",
    "\n",
    "plt.xlabel(\"YearBuilt\")\n",
    "plt.ylabel(\"SiteEUIWN(kBtu/sf)\")\n",
    "plt.title(\"Scatter plot : YearBuilt vs SiteEUIWN(kBtu/sf)\" )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# **Outliers?**\n",
    "\n",
    "# #### Lien entre la consommation énergétique & celle mise à jour via la météo\n",
    "\n",
    "# In[54]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(df[\"SiteEnergyUseWN(kBtu)\"], df[\"SiteEnergyUse(kBtu)\"])\n",
    "\n",
    "plt.xlabel(\"SiteEnergyUseWN(kBtu)\")\n",
    "plt.ylabel(\"SiteEnergyUse\")\n",
    "plt.title(\"Relation entre SiteEnergyUseWN(kBtu) et SiteEnergyUse\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Au vu de la courbe, on peut déduire qu'il y a un ratio entre SiteEnergyUse et SiteEnergyUseWN\n",
    "\n",
    "# Regardez valeur proche de 0 & clean\n",
    "\n",
    "# In[55]:\n",
    "\n",
    "\n",
    "df = building_consumption_clean.copy()\n",
    "\n",
    "clean_df = df[[\"SiteEnergyUseWN(kBtu)\", \"SiteEnergyUse(kBtu)\"]].copy()\n",
    "\n",
    "clean_df[\"SiteEnergyUseWN(kBtu)\"].replace(0, np.nan, inplace=True)\n",
    "\n",
    "clean_df[\"ratio\"] = clean_df[\"SiteEnergyUse(kBtu)\"] / clean_df[\"SiteEnergyUseWN(kBtu)\"]\n",
    "\n",
    "clean_df = clean_df.dropna(subset=[\"ratio\"])\n",
    "\n",
    "mean_ratio = clean_df[\"ratio\"].mean()\n",
    "mean_ratio\n",
    "\n",
    "\n",
    "# In[56]:\n",
    "\n",
    "\n",
    "ratio = 0.95\n",
    "\n",
    "\n",
    "# **Mise à jour du DF avec ce ratio pour remplir toutes les lignes**\n",
    "\n",
    "# In[57]:\n",
    "\n",
    "\n",
    "building_consumption_clean.loc[\n",
    "    (building_consumption_clean[\"SiteEnergyUse(kBtu)\"].isna() | (building_consumption_clean[\"SiteEnergyUse(kBtu)\"] == 0)) &\n",
    "    (building_consumption_clean[\"SiteEnergyUseWN(kBtu)\"].notna() & (building_consumption_clean[\"SiteEnergyUseWN(kBtu)\"] != 0)),\n",
    "    \"SiteEnergyUse(kBtu)\"\n",
    "] = building_consumption_clean[\"SiteEnergyUseWN(kBtu)\"] * ratio\n",
    "\n",
    "\n",
    "# In[58]:\n",
    "\n",
    "\n",
    "building_consumption_clean.loc[\n",
    "    (building_consumption_clean[\"SiteEnergyUseWN(kBtu)\"].isna() | (building_consumption_clean[\"SiteEnergyUseWN(kBtu)\"] == 0)) &\n",
    "    (building_consumption_clean[\"SiteEnergyUse(kBtu)\"].notna() & (building_consumption_clean[\"SiteEnergyUse(kBtu)\"] != 0)),\n",
    "    \"SiteEnergyUseWN(kBtu)\"\n",
    "] = building_consumption_clean[\"SiteEnergyUse(kBtu)\"] / ratio\n",
    "\n",
    "\n",
    "# #### Lien entre la consommation énergétique et la surface totale\n",
    "\n",
    "# In[59]:\n",
    "\n",
    "\n",
    "building_consumption_clean[\"SiteEnergyUseWN(kBtu/sf)\"] = df[\"SiteEnergyUseWN(kBtu)\"] / df[\"PropertyGFATotal\"].replace(0, np.nan)\n",
    "\n",
    "\n",
    "# In[60]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(\n",
    "    data=building_consumption_clean,\n",
    "    x=\"PropertyGFATotal\",\n",
    "    y=\"SiteEnergyUseWN(kBtu/sf)\",\n",
    "    scatter_kws={\"alpha\": 0.3},\n",
    "    line_kws={\"linewidth\": 2}\n",
    ")\n",
    "\n",
    "plt.title(\"Relation entre SiteEnergyUseWN(kBtu/sf) et PropertyGFATotal\")\n",
    "plt.xlabel(\"Surface totale du bâtiment (GFA Total)\")\n",
    "plt.ylabel(\"Consommation d'énergie normalisée (kBtu)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[61]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(\n",
    "    data=building_consumption_clean,\n",
    "    x=\"TotalGHGEmissions\",\n",
    "    y=\"PropertyGFATotal\",\n",
    "    scatter_kws={\"alpha\": 0.3},\n",
    "    line_kws={\"linewidth\": 2}\n",
    ")\n",
    "\n",
    "plt.title(\"Relation entre TotalGHGEmissions et PropertyGFATotal\")\n",
    "plt.xlabel(\"PropertyGFATotal\")\n",
    "plt.ylabel(\"TotalGHGEmissions)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[62]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(\n",
    "    data=building_consumption_clean,\n",
    "    x=\"TotalGHGEmissions\",\n",
    "    y=\"SiteEnergyUseWN(kBtu/sf)\",\n",
    "    scatter_kws={\"alpha\": 0.3},\n",
    "    line_kws={\"linewidth\": 2}\n",
    ")\n",
    "\n",
    "plt.title(\"Relation entre SiteEnergyUseWN(kBtu/sf) et TotalGHGEmissions\")\n",
    "plt.xlabel(\"TotalGHGEmissions\")\n",
    "plt.ylabel(\"Consommation d'énergie normalisée (kBtu)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[63]:\n",
    "\n",
    "\n",
    "df = building_consumption_clean\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(df[\"SiteEnergyUseWN(kBtu/sf)\"], df[\"PropertyGFATotal\"])\n",
    "\n",
    "plt.xlabel(\"PropertyGFATotal\")\n",
    "plt.ylabel(\"SiteEnergyUseWN(kBtu/sf)\")\n",
    "plt.title(\"Relation entre SiteEnergyUseWN(kBtu/sf) et PropertyGFATotal\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# On ne peut pas déduire de relation entre la surface totale du bâtiment et la consommation énergétique\n",
    "\n",
    "# #### Lien entre la consommation énergétique et l'année de construction\n",
    "\n",
    "# In[64]:\n",
    "\n",
    "\n",
    "df = building_consumption_clean.copy()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(df[\"SiteEnergyUseWN(kBtu/sf)\"], df[\"YearBuilt\"])\n",
    "\n",
    "plt.xlabel(\"SiteEnergyUseWN(kBtu/sf)\")\n",
    "plt.ylabel(\"YearBuilt\")\n",
    "plt.title(\"Relation entre SiteEnergyUseWN(kBtu/sf) et YearBuilt\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# On ne peut pas déduire de relation entre l'année de construction et la consommation électrique\n",
    "\n",
    "# In[65]:\n",
    "\n",
    "\n",
    "df[\"YearBuilt_10\"] = (df[\"YearBuilt\"] // 10) * 10\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.boxplot(\n",
    "    data=df,\n",
    "    x=\"YearBuilt_10\",\n",
    "    y=\"SiteEnergyUseWN(kBtu/sf)\"\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Année de construction (tranches de 10 ans)\")\n",
    "plt.ylabel(\"SiteEnergyUseWN (kBtu/sf)\")\n",
    "plt.title(\"Distribution de la consommation normalisée par tranche de 10 ans\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# faire des box plot par créneau de 10 ans & par surface\n",
    "\n",
    "# #### Distribution de la consommation énergétique\n",
    "\n",
    "# In[66]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.hist(\n",
    "    building_consumption_clean[\"SiteEnergyUseWN(kBtu)\"].dropna(),\n",
    "    bins=25\n",
    ")\n",
    "\n",
    "plt.title(\"Distribution de SiteEnergyUseWN (kBtu)\")\n",
    "plt.xlabel(\"SiteEnergyUseWN (kBtu)\")\n",
    "plt.ylabel(\"Nombre de bâtiments\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# On remarque que la majorité des bâtiments consomment peu, sauf quelques uns qui semblent avoir des valeurs extrèment évelvés.\n",
    "\n",
    "# In[67]:\n",
    "\n",
    "\n",
    "seuil = 0.75e8\n",
    "df = building_consumption_clean.copy()\n",
    "df[df[\"SiteEnergyUseWN(kBtu)\"] > seuil]\n",
    "\n",
    "\n",
    "# #### Distribution de la surface totale\n",
    "\n",
    "# In[68]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.hist(\n",
    "    building_consumption_clean[\"PropertyGFATotal\"].dropna(),\n",
    "    bins=50\n",
    ")\n",
    "\n",
    "plt.title(\"Distribution de PropertyGFATotal\")\n",
    "plt.xlabel(\"PropertyGFATotal\")\n",
    "plt.ylabel(\"Nombre de bâtiments\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Quelques bâtiments ont une taille bien plus importantes que les autres.\n",
    "\n",
    "# In[69]:\n",
    "\n",
    "\n",
    "seuil = 0.75e6\n",
    "df = building_consumption_clean.copy()\n",
    "df[df[\"PropertyGFATotal\"] > seuil]\n",
    "\n",
    "\n",
    "# #### Distribution de la surface des bâtiments\n",
    "\n",
    "# In[70]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.hist(\n",
    "    building_consumption_clean[\"PropertyGFABuilding(s)\"].dropna(),\n",
    "    bins=50\n",
    ")\n",
    "\n",
    "plt.title(\"Distribution de PropertyGFABuilding(s)\")\n",
    "plt.xlabel(\"PropertyGFABuilding(s)\")\n",
    "plt.ylabel(\"Nombre de bâtiments\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# On retrouve une courbe similaire pour la surface qui ne correspond uniquement au bâtiment (sans les parking)\n",
    "\n",
    "# In[71]:\n",
    "\n",
    "\n",
    "seuil = 0.75e6\n",
    "df = building_consumption_clean.copy()\n",
    "df[df[\"PropertyGFABuilding(s)\"] > seuil]\n",
    "\n",
    "\n",
    "# In[72]:\n",
    "\n",
    "\n",
    "df[df[\"PropertyGFABuilding(s)\"] > seuil][\"PrimaryPropertyType\"].unique()\n",
    "\n",
    "\n",
    "# #### Distribution de la consommation énergétique en fonction de la fonction première des bâtiments\n",
    "\n",
    "# In[73]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "\n",
    "df_plot = building_consumption_clean[[\"PrimaryPropertyType\", \"SiteEnergyUseWN(kBtu/sf)\"]].dropna()\n",
    "\n",
    "groups = [group[\"SiteEnergyUseWN(kBtu/sf)\"].values \n",
    "          for name, group in df_plot.groupby(\"PrimaryPropertyType\")]\n",
    "\n",
    "labels = df_plot.groupby(\"PrimaryPropertyType\").groups.keys()\n",
    "\n",
    "plt.boxplot(groups, labels=labels, vert=True)\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Distribution de SiteEnergyUseWN(kBtu/sf)  par PrimaryPropertyType\")\n",
    "plt.ylabel(\"SiteEUIWN(kBtu/sf)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Les hôpitaux sont les plus gros consommateurs d'énergie. faire par surface\n",
    "\n",
    "# In[74]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "\n",
    "df_plot = building_consumption_clean[[\"LargestPropertyUseType\", \"SiteEnergyUseWN(kBtu/sf)\"]].dropna()\n",
    "\n",
    "groups = [group[\"SiteEnergyUseWN(kBtu/sf)\"].values \n",
    "          for name, group in df_plot.groupby(\"LargestPropertyUseType\")]\n",
    "\n",
    "labels = df_plot.groupby(\"LargestPropertyUseType\").groups.keys()\n",
    "\n",
    "plt.boxplot(groups, labels=labels, vert=True)\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Distribution de SiteEnergyUseWN(kBtu/sf) par LargestPropertyUseType\")\n",
    "plt.ylabel(\"SiteEnergyUseWN(kBtu/sf)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Les hôpitaux et les Data Center sont les plus gros consommateur d'énergie\n",
    "\n",
    "# #### Proportion de LargestPropertyUse et PropertyGFA total \n",
    "\n",
    "# In[75]:\n",
    "\n",
    "\n",
    "surface_total = df['PropertyGFATotal'].copy()\n",
    "\n",
    "surface_total.replace(0, np.nan, inplace=True)\n",
    "\n",
    "df['Proportion_LargestUse_to_TotalGFA'] = df['LargestPropertyUseTypeGFA'] / surface_total\n",
    "df['Proportion_LargestUse_to_TotalGFA'].fillna(0)\n",
    "\n",
    "\n",
    "# In[76]:\n",
    "\n",
    "\n",
    "proportion_percent = df['Proportion_LargestUse_to_TotalGFA'] * 100\n",
    "proportion_percent = np.minimum(proportion_percent, 100)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Création de l'histogramme avec la colonne PLAFONNÉE\n",
    "sns.histplot(proportion_percent, bins=50, kde=True, color='purple', edgecolor='black')\n",
    "\n",
    "plt.title(\"Distribution de la Proportion d'Usage Principal\", fontsize=16)\n",
    "plt.xlabel(\"Proportion de l'Usage Principal par Rapport à la Surface Totale (%)\", fontsize=12)\n",
    "plt.ylabel(\"Nombre de Bâtiments (Fréquence)\", fontsize=12)\n",
    "plt.xlim(0, 105) # Limiter l'axe X pour bien voir l'effet du plafonnement\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[77]:\n",
    "\n",
    "\n",
    "surface_total = df['PropertyGFATotal'].copy()\n",
    "\n",
    "surface_total.replace(0, np.nan, inplace=True)\n",
    "\n",
    "df['Proportion_SecondUse_to_TotalGFA'] = df['SecondLargestPropertyUseTypeGFA'] / surface_total\n",
    "df['Proportion_SecondUse_to_TotalGFA'].fillna(0)\n",
    "\n",
    "\n",
    "# In[78]:\n",
    "\n",
    "\n",
    "proportion_percent = df['Proportion_SecondUse_to_TotalGFA'] * 100\n",
    "proportion_percent = np.minimum(proportion_percent, 100)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.histplot(proportion_percent, bins=50, kde=True, color='blue', edgecolor='black')\n",
    "\n",
    "plt.title(\"Distribution de la Proportion d'usage Secondaire Principal\", fontsize=16)\n",
    "plt.xlabel(\"Proportion de l'Usage Secondaire par Rapport à la Surface Totale (%)\", fontsize=12)\n",
    "plt.ylabel(\"Nombre de Bâtiments (Fréquence)\", fontsize=12)\n",
    "plt.xlim(0, 105)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[79]:\n",
    "\n",
    "\n",
    "surface_total = df['PropertyGFATotal'].copy()\n",
    "\n",
    "surface_total.replace(0, np.nan, inplace=True)\n",
    "\n",
    "df['Proportion_ThirdUse_to_TotalGFA'] = df['ThirdLargestPropertyUseTypeGFA'] / surface_total\n",
    "df['Proportion_ThirdUse_to_TotalGFA'].fillna(0)\n",
    "\n",
    "\n",
    "# In[80]:\n",
    "\n",
    "\n",
    "proportion_percent = df['Proportion_ThirdUse_to_TotalGFA'] * 100\n",
    "proportion_percent = np.minimum(proportion_percent, 100)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "sns.histplot(proportion_percent, bins=50, kde=True, color='red', edgecolor='black')\n",
    "\n",
    "plt.title(\"Distribution de la Proportion au 3ème usage\", fontsize=16)\n",
    "plt.xlabel(\"Proportion du Troisième Usage par Rapport à la Surface Totale (%)\", fontsize=12)\n",
    "plt.ylabel(\"Nombre de Bâtiments (Fréquence)\", fontsize=12)\n",
    "plt.xlim(0, 105) \n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# La proportion du Troisième Usage étant globalement faible, il ne sera pas la peine de la prendre en compte pour notre modèle prédictif.\n",
    "\n",
    "# #### TERMINER L'ANALYSE EXPLORATOIRE \n",
    "\n",
    "# A réaliser : \n",
    "# - Une analyse descriptive des données, y compris une explication du sens des colonnes gardées, des arguments derrière la suppression de lignes ou de colonnes, des statistiques descriptives et des visualisations pertinentes.\n",
    "\n",
    "# ### Import des modules \n",
    "\n",
    "# In[81]:\n",
    "\n",
    "\n",
    "#Selection\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV, \n",
    "    cross_validate,\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error \n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "#Preprocess\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "\n",
    "#Modèles\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# # Modélisation \n",
    "\n",
    "# ### Feature Engineering\n",
    "\n",
    "# A réaliser : Enrichir le jeu de données actuel avec de nouvelles features issues de celles existantes. \n",
    "\n",
    "# ### Préparation des features pour la modélisation\n",
    "\n",
    "# A réaliser :\n",
    "# * Si ce n'est pas déjà fait, supprimer toutes les colonnes peu pertinentes pour la modélisation.\n",
    "# * Tracer la distribution de la cible pour vous familiariser avec l'ordre de grandeur. En cas d'outliers, mettez en place une démarche pour les supprimer.\n",
    "# * Débarrassez-vous des features redondantes en utilisant une matrice de corrélation.\n",
    "# * Réalisez différents graphiques pour comprendre le lien entre vos features et la target (boxplots, scatterplots, pairplot si votre nombre de features numériques n'est pas très élevé).\n",
    "# *  Séparez votre jeu de données en un Pandas DataFrame X (ensemble de feautures) et Pandas Series y (votre target).\n",
    "# * Si vous avez des features catégorielles, il faut les encoder pour que votre modèle fonctionne.\n",
    "\n",
    "# #### Première Régression Linéaire\n",
    "\n",
    "# In[83]:\n",
    "\n",
    "\n",
    "df = building_consumption_clean.copy()\n",
    "\n",
    "\n",
    "# In[84]:\n",
    "\n",
    "\n",
    "# Cible que l'on veut calculer\n",
    "target = 'SiteEnergyUseWN(kBtu)'\n",
    "\n",
    "# On supprime la target + les colonnes n'apportant aucunes valeurs ajouté\n",
    "columns_to_drop = [target, 'OSEBuildingID', 'PropertyName', 'SiteEnergyUse(kBtu)'] \n",
    "\n",
    "X = df.drop(columns=columns_to_drop, errors='ignore') \n",
    "y = df[target]\n",
    "\n",
    "\n",
    "# In[85]:\n",
    "\n",
    "\n",
    "# On définit les colonnes numériques et catégorielles en fonction de si ce sont des nombres ou des strings.\n",
    "numeric_columns = X.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_columns = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "\n",
    "# In[86]:\n",
    "\n",
    "\n",
    "# La régression linéaire n'accepte pas les valeurs NaN\n",
    "# Certaines colonnes contiennent des NaN : on les transforme avec la valeur médianne\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "# On transforme les colonnes catégorielles en suite de nombre binaire. On remplace les valeurs NaN par \"missing\"\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# In[87]:\n",
    "\n",
    "\n",
    "# On fait un prétraitement des données:\n",
    "# On applique les pipelines de transformation aux colonnes numériques et catégorielles.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_columns),\n",
    "        (\"cat\", categorical_transformer, categorical_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# In[88]:\n",
    "\n",
    "\n",
    "# On définit le pipeline avec le prétraitement des données et le modèle de régression linéaire.\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "# In[89]:\n",
    "\n",
    "\n",
    "# On entraîne tout le pipeline sur les données X (features) et y (la cible).\n",
    "pipeline.fit(X, y)\n",
    "# On produit les prédictions du modèle sur X.\n",
    "y_prediction = pipeline.predict(X)\n",
    "\n",
    "\n",
    "# In[90]:\n",
    "\n",
    "\n",
    "# Erreur Quadratique Moyenne (Mean Squared Error - MSE)\n",
    "# Calcule la moyenne des carrés des erreurs.\n",
    "mse = mean_squared_error(y, y_prediction)\n",
    "\n",
    "# Racine Carrée de l'Erreur Quadratique Moyenne (Root Mean Squared Error - RMSE)\n",
    "# La métrique la plus lisible car dans l'unité de la cible (kBtu).\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Erreur Absolue Moyenne (Mean Absolute Error - MAE)\n",
    "# Calcule la moyenne de la valeur absolue des erreurs. Moins sensible aux outliers que l'RMSE.\n",
    "mae = mean_absolute_error(y, y_prediction)\n",
    "\n",
    "# Coefficient de Détermination (R-carré - R2)\n",
    "# Représente la proportion de la variance expliquée par le modèle.\n",
    "r2 = r2_score(y, y_prediction)\n",
    "\n",
    "# 3. Affichage des résultats\n",
    "print(\"Mesures  du Modèle sur l'Ensemble Complet (Nettoyé) :\")\n",
    "print(f\"R-carré (R2) : {r2:.4f}\")\n",
    "print(f\"Erreur Quadratique Moyenne (RMSE) : {rmse:.2f} kBtu\")\n",
    "print(f\"Erreur Absolue Moyenne (MAE) : {mae:.2f} kBtu\")\n",
    "\n",
    "\n",
    "# Le R² étant proche de 1, on peut dire que notre *algorithme fonctionne*, mais le score étant presque parfait, il y a du **data leakage**.\n",
    "\n",
    "# In[91]:\n",
    "\n",
    "\n",
    "# Nom de la colonne cible \n",
    "target_column_name_brute = 'SiteEnergyUseWN(kBtu)'\n",
    "\n",
    "# On récupère les valeurs réelles de la colonne cible dans le DataFrame original df.\n",
    "y_reel_brut = df.loc[X.index, target_column_name_brute]\n",
    "\n",
    "\n",
    "# In[92]:\n",
    "\n",
    "\n",
    "# On transforme les prédictions du modèle en une Series Pandas.\n",
    "y_pred_series = pd.Series(y_prediction)\n",
    "\n",
    "\n",
    "# In[93]:\n",
    "\n",
    "\n",
    "# On récupère l’index original du DataFrame X afin de pouvoir ré-aligner les prédictions avec les bonnes lignes du dataset.\n",
    "index_final = X.index \n",
    "\n",
    "# On utilise le pipeline entraîné pour prédire la variable cible sur toutes les lignes de X.\n",
    "\n",
    "y_pred_brut_model = pipeline.predict(X)\n",
    "\n",
    "# On transforme les prédictions en Series Pandas, avec l'index d’origine.\n",
    "y_pred_series = pd.Series(y_pred_brut_model, index=index_final)\n",
    "\n",
    "# On extrait les valeurs réelles de la colonne cible dans le DataFrame initial df,\n",
    "# mais uniquement pour les lignes qui correspondent à celles utilisées dans X.\n",
    "y_reel_brut = df.loc[X.index, target_column_name_brute] \n",
    "\n",
    "# On crée un tableau qui regroupe valeur réelle vs valeur prédite pour chaque ligne.\n",
    "results_df= pd.DataFrame({\n",
    "    'Y_Réel_Brut': y_reel_brut, \n",
    "    'Y_Prédit': y_pred_series, \n",
    "})\n",
    "# On calcule l’erreur brute = réel – prédit\n",
    "results_df['Erreur'] = results_df['Y_Réel_Brut'] - results_df['Y_Prédit']\n",
    "results_df['Erreur_Absolue'] = np.abs(results_df['Erreur'])\n",
    "\n",
    "# On regarde le top 10 des erreurs\n",
    "top_10_erreurs = results_df.sort_values(by='Erreur_Absolue', ascending=False).head(10)\n",
    "\n",
    "\n",
    "top_10_erreurs\n",
    "\n",
    "\n",
    "\n",
    "# In[94]:\n",
    "\n",
    "\n",
    "# On cherche dans le DF de base les bâtiments correspondant aux top 10 des erreurs.\n",
    "X_erreurs_brutes = df.loc[top_10_erreurs.index]\n",
    "\n",
    "# On choisit les colonnes que l'on veut afficher\n",
    "X_erreurs_brutes[['BuildingType', 'LargestPropertyUseType', 'PropertyGFATotal', 'Neighborhood']]\n",
    "\n",
    "\n",
    "# On remarque qu'il a des **Hôpitaux**, mais également beaucoup de bureaux se trouvant à **Downton** et des bâtimens se trouvant à **NorthWest**\n",
    "\n",
    "# ### Comparaison de différents modèles supervisés\n",
    "\n",
    "# A réaliser :\n",
    "# * Pour chaque algorithme que vous allez tester, vous devez :\n",
    "#     * Réaliser au préalable une séparation en jeu d'apprentissage et jeu de test via une validation croisée.\n",
    "#     * Si les features quantitatives que vous souhaitez utiliser ont des ordres de grandeur très différents les uns des autres, et que vous utilisez un algorithme de regression qui est sensible à cette différence, alors il faut réaliser un scaling (normalisation) de la donnée au préalable.\n",
    "#     * Entrainer le modèle sur le jeu de Train\n",
    "#     * Prédire la cible sur la donnée de test (nous appelons cette étape, l'inférence).\n",
    "#     * Calculer les métriques de performance R2, MAE et RMSE sur le jeu de train et de test.\n",
    "#     * Interpréter les résultats pour juger de la fiabilité de l'algorithme.\n",
    "# * Vous pouvez choisir par exemple de tester un modèle linéaire, un modèle à base d'arbres et un modèle de type SVM\n",
    "# * Déterminer le modèle le plus performant parmi ceux testés.\n",
    "\n",
    "# In[95]:\n",
    "\n",
    "\n",
    "df = building_consumption_clean.copy()\n",
    "\n",
    "\n",
    "# In[96]:\n",
    "\n",
    "\n",
    "target = 'SiteEnergyUseWN(kBtu)'\n",
    "columns_to_drop = [target, 'OSEBuildingID', 'PropertyName'] \n",
    "df = df.drop(columns=columns_to_drop, errors='ignore') \n",
    "\n",
    "\n",
    "# #### Matrice de Pearson\n",
    "\n",
    "# In[97]:\n",
    "\n",
    "\n",
    "colonnes_correlation = [\n",
    "    'PropertyGFATotal', \n",
    "    'YearBuilt', \n",
    "    'NumberofFloors',\n",
    "    'ENERGYSTARScore', \n",
    "    'SiteEnergyUseWN(kBtu)', \n",
    "    'SiteEnergyUse(kBtu)', \n",
    "    'TotalGHGEmissions',\n",
    "    'SteamUse(kBtu)', \n",
    "    'Electricity(kBtu)',\n",
    "    'NaturalGas(kBtu)',\n",
    "    'GHGEmissionsIntensity',\n",
    "    'SiteEUI(kBtu/sf)', \n",
    "    'SiteEUIWN(kBtu/sf)',\n",
    "    'SourceEUI(kBtu/sf)', \n",
    "    'SourceEUIWN(kBtu/sf)',\n",
    "]\n",
    "\n",
    "df_corr = building_consumption_clean[colonnes_correlation].copy()\n",
    "\n",
    "# 2. Calcul de la matrice de corrélation\n",
    "matrice_corr = df_corr.corr(method='pearson')\n",
    "\n",
    "# 3. Visualisation (Heatmap)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    matrice_corr, \n",
    "    annot=True, \n",
    "    cmap='coolwarm', \n",
    "    fmt=\".2f\",\n",
    "    linewidths=.5,\n",
    ")\n",
    "plt.title('Matrice de Corrélation')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Regardons maintenant les colonnes que l'on peut supprimer dans notre DF pour avoir une meilleure analyse. Elle risque de mal entraîner le modèle car elles sont trop ou peu corrélés avec notre cible.\n",
    "\n",
    "# In[98]:\n",
    "\n",
    "\n",
    "columns_to_drop = [\n",
    "    'SiteEnergyUse(kBtu)', \n",
    "    'SteamUse(kBtu)', \n",
    "    'Electricity(kBtu)',\n",
    "    'NaturalGas(kBtu)',\n",
    "    'TotalGHGEmissions', \n",
    "    'GHGEmissionsIntensity',\n",
    "    'SiteEUI(kBtu/sf)', \n",
    "    'SiteEUIWN(kBtu/sf)',\n",
    "    'SourceEUI(kBtu/sf)', \n",
    "    'SourceEUIWN(kBtu/sf)',\n",
    "]\n",
    "df = df.drop(columns=columns_to_drop, errors='ignore') \n",
    "df.columns\n",
    "\n",
    "\n",
    "# #### Distribution de la valeur cible\n",
    "\n",
    "# On a remarqué précedemment qu'il y avait des outliers sur la consommation énergétique (SiteEnergyUseWN(kBtu)) , il faut donc utiliser le principe de windorization pour réduire l'impact des valeurs extrêmes sans supprimer les lignes.\n",
    "\n",
    "# In[99]:\n",
    "\n",
    "\n",
    "df_outliers = building_consumption_clean.copy()\n",
    "\n",
    "\n",
    "# In[100]:\n",
    "\n",
    "\n",
    "target_column_name = \"SiteEnergyUseWN(kBtu)\"\n",
    "df_outliers = df_outliers[target_column_name].dropna()\n",
    "\n",
    "quantile_sup = df_outliers.quantile(0.95)\n",
    "df_outliers_winsorized = df_outliers.clip(upper=quantile_sup)\n",
    "\n",
    "\n",
    "# In[101]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.hist(\n",
    "    df_outliers_winsorized,\n",
    "    bins=25\n",
    ")\n",
    "\n",
    "plt.title(\"Distribution de SiteEnergyUseWN (kBtu)\")\n",
    "plt.xlabel(\"SiteEnergyUseWN (kBtu)\")\n",
    "plt.ylabel(\"Nombre de bâtiments\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Nous avons vu précédemment qu'il y a avait des outliers sur PropertyGFATotal. On applique la même méthode que précedemmment\n",
    "\n",
    "# In[102]:\n",
    "\n",
    "\n",
    "df_outliers_gfa = building_consumption_clean.copy()\n",
    "\n",
    "\n",
    "# In[103]:\n",
    "\n",
    "\n",
    "target_column_name = \"PropertyGFATotal\"\n",
    "df_outliers_gfa = df_outliers_gfa[target_column_name].dropna()\n",
    "\n",
    "quantile_sup = df_outliers_gfa.quantile(0.95)\n",
    "df_outliers_gfa_winsorized = df_outliers_gfa.clip(upper=quantile_sup)\n",
    "\n",
    "\n",
    "# In[104]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.hist(\n",
    "    df_outliers_gfa_winsorized,\n",
    "    bins=25\n",
    ")\n",
    "\n",
    "plt.title(\"Distribution de PropertyGFATotal\")\n",
    "plt.xlabel(\"PropertyGFATotal\")\n",
    "plt.ylabel(\"Nombre de bâtiments\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# On remarque qu'il n'y a plus d'Outlier. On peut donc appliquer cette méthode à notre DF.\n",
    "\n",
    "# ##### Winsorisation\n",
    "\n",
    "# In[105]:\n",
    "\n",
    "\n",
    "df = building_consumption_clean.copy()\n",
    "\n",
    "\n",
    "# In[106]:\n",
    "\n",
    "\n",
    "target_column_name = 'SiteEnergyUseWN(kBtu)'\n",
    "target_column_name_winsorized = 'SiteEnergyUseWM(kBtu)_winsorized'\n",
    "\n",
    "outliers = df[target_column_name].dropna()\n",
    "quantile_sup = outliers.quantile(0.95)\n",
    "\n",
    "df[target_column_name_winsorized] = df[target_column_name]\n",
    "\n",
    "outliers_winsorized_serie = outliers.clip(upper=quantile_sup)\n",
    "\n",
    "df.loc[outliers_winsorized_serie.index, target_column_name_winsorized] = outliers_winsorized_serie\n",
    "\n",
    "y_final = df[target_column_name_winsorized].dropna()\n",
    "\n",
    "\n",
    "# In[107]:\n",
    "\n",
    "\n",
    "target_column_name_gfa = 'PropertyGFATotal'\n",
    "target_column_name_gfa_winsorized = 'PropertyGFATotal_winsorized'\n",
    "\n",
    "outliers_gfa = df[target_column_name_gfa].dropna()\n",
    "quantile_sup = outliers_gfa.quantile(0.95)\n",
    "\n",
    "df[target_column_name_gfa_winsorized] = df[target_column_name_gfa]\n",
    "\n",
    "outliers_winsorized_gfa_serie = outliers_gfa.clip(upper=quantile_sup)\n",
    "\n",
    "df.loc[outliers_winsorized_gfa_serie.index, target_column_name_gfa_winsorized] = outliers_winsorized_gfa_serie\n",
    "\n",
    "y_final_gfa = df[target_column_name_gfa_winsorized].dropna()\n",
    "\n",
    "\n",
    "# In[108]:\n",
    "\n",
    "\n",
    "data_leakage_columns = [\n",
    "    'SiteEUI(kBtu/sf)', 'SiteEUIWN(kBtu/sf)', 'SourceEUI(kBtu/sf)', 'SourceEUIWN(kBtu/sf)',\n",
    "    'SiteEnergyUse(kBtu)', 'SteamUse(kBtu)', 'Electricity(kBtu)', 'NaturalGas(kBtu)',\n",
    "    'TotalGHGEmissions', 'GHGEmissionsIntensity', 'ENERGYSTARScore', 'YearsENERGYSTARCertified',\n",
    "    'SiteEnergyUseWN(kBtu/sf)',\n",
    "    'SiteEnergyUseWM(kBtu)'\n",
    "]\n",
    "\n",
    "columns_to_drop = [\n",
    "    'OSEBuildingID', 'PropertyName', 'PrimaryPropertyType', 'NumberofBuildings',\n",
    "    'PropertyGFAParking', 'PropertyGFABuilding(s)', 'ListOfAllPropertyUseTypes',\n",
    "    'ThirdLargestPropertyUseType', 'ThirdLargestPropertyUseTypeGFA'\n",
    "]\n",
    "\n",
    "column_target = [target_column_name, target_column_name_winsorized, target_column_name_gfa] \n",
    "\n",
    "features_to_drop = list(set(data_leakage_columns + columns_to_drop + column_target))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = df.drop(columns=features_to_drop, errors='ignore')\n",
    "\n",
    "\n",
    "X = X.loc[y_final.index]\n",
    "\n",
    "\n",
    "# In[109]:\n",
    "\n",
    "\n",
    "numeric_columns = X.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_columns = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_columns),\n",
    "        (\"cat\", categorical_transformer, categorical_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "y_prediction = pipeline.predict(X)\n",
    "\n",
    "\n",
    "# In[110]:\n",
    "\n",
    "\n",
    "# Erreur Quadratique Moyenne (Mean Squared Error - MSE)\n",
    "# Calcule la moyenne des carrés des erreurs.\n",
    "mse = mean_squared_error(y, y_prediction)\n",
    "\n",
    "# Racine Carrée de l'Erreur Quadratique Moyenne (Root Mean Squared Error - RMSE)\n",
    "# La métrique la plus lisible car dans l'unité de la cible (kBtu).\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Erreur Absolue Moyenne (Mean Absolute Error - MAE)\n",
    "# Calcule la moyenne de la valeur absolue des erreurs. Moins sensible aux outliers que l'RMSE.\n",
    "mae = mean_absolute_error(y, y_prediction)\n",
    "\n",
    "# Coefficient de Détermination (R-carré - R2), doit être proche de 1.\n",
    "# Représente la proportion de la variance expliquée par le modèle.\n",
    "r2 = r2_score(y, y_prediction)\n",
    "\n",
    "# 3. Affichage des résultats\n",
    "print(\"Mesures  du Modèle sur l'Ensemble Complet après windorization :\")\n",
    "print(f\"R-carré (R2) : {r2:.4f}\")\n",
    "print(f\"Erreur Quadratique Moyenne (RMSE) : {rmse:.2f} kBtu\")\n",
    "print(f\"Erreur Absolue Moyenne (MAE) : {mae:.2f} kBtu\")\n",
    "\n",
    "\n",
    "# On retrouve un R de 0.747, ce qui est beaucoup plus cohérent.\n",
    "\n",
    "# In[111]:\n",
    "\n",
    "\n",
    "# CODE COMPARAISON DES MODELES\n",
    "\n",
    "\n",
    "# ### Optimisation et interprétation du modèle\n",
    "\n",
    "# A réaliser :\n",
    "# * Reprennez le meilleur algorithme que vous avez sécurisé via l'étape précédente, et réalisez une GridSearch de petite taille sur au moins 3 hyperparamètres.\n",
    "# * Si le meilleur modèle fait partie de la famille des modèles à arbres (RandomForest, GradientBoosting) alors utilisez la fonctionnalité feature importance pour identifier les features les plus impactantes sur la performance du modèle. Sinon, utilisez la méthode Permutation Importance de sklearn. \n",
    "\n",
    "# In[112]:\n",
    "\n",
    "\n",
    "# CODE OPTIMISATION ET INTERPRETATION DU MODELE\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
